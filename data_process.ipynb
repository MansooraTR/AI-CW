{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(images), np\u001b[38;5;241m.\u001b[39marray(labels)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Define the indices or IDs for each set\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m train_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[43mn_train\u001b[49m))  \u001b[38;5;66;03m# Replace n_train with the number of images in the training set\u001b[39;00m\n\u001b[0;32m     25\u001b[0m val_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(n_train, n_train \u001b[38;5;241m+\u001b[39m n_val))  \u001b[38;5;66;03m# Replace n_val with the number of images in the validation set\u001b[39;00m\n\u001b[0;32m     26\u001b[0m test_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(n_train \u001b[38;5;241m+\u001b[39m n_val, n_total))  \u001b[38;5;66;03m# Replace n_total with the total number of images in the dataset\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'n_train' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Define preprocessing functions\n",
    "def preprocess_image(image_path, target_size=(224, 224)):\n",
    "    img = Image.open(image_path)\n",
    "    img = img.resize(target_size)\n",
    "    img_array = np.array(img) / 255.0  # Normalize pixel values to [0, 1]\n",
    "    return img_array\n",
    "\n",
    "def load_images_and_labels(image_folder, label_file, ids):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for image_id in ids:\n",
    "        image_file = os.path.join(image_folder, f'image_{image_id + 1}.jpg')  # Adjust index to start from 1\n",
    "        image = preprocess_image(image_file)\n",
    "        images.append(image)\n",
    "        labels.append(labels[image_id])  # Assuming labels are loaded separately\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Define the indices or IDs for each set\n",
    "train_ids = list(range(0, n_train))  # Replace n_train with the number of images in the training set\n",
    "val_ids = list(range(n_train, n_train + n_val))  # Replace n_val with the number of images in the validation set\n",
    "test_ids = list(range(n_train + n_val, n_total))  # Replace n_total with the total number of images in the dataset\n",
    "\n",
    "# Shuffle the data splits if needed\n",
    "train_ids = shuffle(train_ids)\n",
    "val_ids = shuffle(val_ids)\n",
    "test_ids = shuffle(test_ids)\n",
    "\n",
    "\n",
    "# Preprocess training, validation, and test sets\n",
    "train_images, train_labels = load_images_and_labels(image_folder, labels, train_ids)\n",
    "val_images, val_labels = load_images_and_labels(image_folder, labels, val_ids)\n",
    "test_images, test_labels = load_images_and_labels(image_folder, labels, test_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the training set: 1020\n",
      "Number of images in the validation set: 1020\n",
      "Number of images in the test set: 6149\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "\n",
    "# Load the setid.mat file\n",
    "setid_data = scipy.io.loadmat('setid.mat')\n",
    "\n",
    "# Extract the data splits (train, val, test)\n",
    "train_ids = setid_data['trnid'][0] - 1  # Adjust indices\n",
    "val_ids = setid_data['valid'][0] - 1   # Adjust indices\n",
    "test_ids = setid_data['tstid'][0] - 1  # Adjust indices\n",
    "\n",
    "# Determine the number of images in each set\n",
    "num_train_images = len(train_ids)\n",
    "num_val_images = len(val_ids)\n",
    "num_test_images = len(test_ids)\n",
    "\n",
    "print(\"Number of images in the training set:\", num_train_images)\n",
    "print(\"Number of images in the validation set:\", num_val_images)\n",
    "print(\"Number of images in the test set:\", num_test_images)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
